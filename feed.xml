<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="cn"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://bci-vr-nju.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://bci-vr-nju.github.io/" rel="alternate" type="text/html" hreflang="cn"/><updated>2024-12-11T11:29:20+00:00</updated><id>https://bci-vr-nju.github.io/feed.xml</id><title type="html">BCI-VR group @ NJU</title><subtitle>The website for the project led by the BCI-VR group at NJU. </subtitle><entry><title type="html">大创项目结题汇报</title><link href="https://bci-vr-nju.github.io/blog/2024/sumup/" rel="alternate" type="text/html" title="大创项目结题汇报"/><published>2024-11-12T18:00:00+00:00</published><updated>2024-11-12T18:00:00+00:00</updated><id>https://bci-vr-nju.github.io/blog/2024/sumup</id><content type="html" xml:base="https://bci-vr-nju.github.io/blog/2024/sumup/"><![CDATA[<h1 id="exploring-the-fusion-of-brain-computer-interface-and-virtual-reality-a-student-innovation-project">Exploring the Fusion of Brain-Computer Interface and Virtual Reality: A Student Innovation Project</h1> <p>In recent years, Brain-Computer Interface (BCI) and Virtual Reality (VR) technologies have emerged as hot topics in both academia and industry. Against this backdrop, our undergraduate innovation team at Nanjing University is combining these two transformative technologies to explore real-time interaction scenarios through a motor imagery (MI)-based BCI system. This blog post provides a comprehensive overview of our project, from its conceptual foundation to technical implementation and beyond.</p> <hr/> <h3 id="1-project-background-bridging-bci-and-vr">1. Project Background: Bridging BCI and VR</h3> <h4 id="what-is-bci">What is BCI?</h4> <p>BCI is a cutting-edge human-computer interaction technology that decodes brain signals, enabling users to communicate directly with computers or external devices through their thoughts. Non-invasive electroencephalography (EEG)-based BCIs have advanced significantly in recent years, driven by innovations in machine learning and deep learning. However, challenges such as individual signal variability, low signal-to-noise ratio (SNR), and limited training datasets continue to hinder the widespread adoption of BCI systems.</p> <h4 id="the-role-of-vr">The Role of VR</h4> <p>VR immerses users in simulated environments using head-mounted displays and other sensory devices. While current VR systems offer unparalleled immersive experiences, navigation within virtual environments often relies on physical controllers or expensive omnidirectional treadmills, which are cumbersome and unnatural for prolonged use.</p> <h4 id="why-combine-bci-and-vr">Why Combine BCI and VR?</h4> <p>By integrating BCI and VR, we aim to address the limitations of both technologies. Imagine navigating a virtual environment purely through thought—a leap in both usability and accessibility. This combination not only introduces novel interaction paradigms but also holds immense potential for democratizing BCI technology.</p> <hr/> <h3 id="2-research-objectives-tackling-key-challenges">2. Research Objectives: Tackling Key Challenges</h3> <h4 id="identifying-key-issues">Identifying Key Issues</h4> <ol> <li><strong>Limitations of VR Mobility</strong>: Current VR navigation systems are unintuitive, expensive, and inaccessible to general users.</li> <li><strong>BCI Accuracy and Latency</strong>: Low classification accuracy and high latency hinder real-time usability in dynamic environments.</li> <li><strong>Individual Variability</strong>: Significant differences in users’ EEG signals challenge model generalization across users.</li> </ol> <h4 id="our-goals">Our Goals</h4> <p>Our project aims to design a real-time interactive BCI system with the following features:</p> <ul> <li>Efficient data acquisition and preprocessing</li> <li>Robust motor imagery classification models</li> <li>Seamless signal-to-control mappings</li> <li>Adaptive calibration for user variability</li> </ul> <hr/> <h3 id="3-technical-framework-and-implementation">3. Technical Framework and Implementation</h3> <h4 id="data-acquisition-and-preprocessing">Data Acquisition and Preprocessing</h4> <p>We used the Emotive EPOC X device to capture EEG signals, employing a structured paradigm:</p> <ul> <li><strong>Data Collection Protocol</strong>: Participants alternate between 4-second rest and 4-second motor imagery tasks. Data below a quality threshold is discarded and re-collected.</li> <li><strong>Preprocessing</strong>: Signals are filtered using Butterworth and bandpass filters (0.05Hz–40Hz) to reduce noise and extract relevant features.</li> </ul> <h4 id="machine-learning-models">Machine Learning Models</h4> <p>To enhance classification accuracy, we adopted an ensemble learning approach, integrating three models using a “voting” mechanism:</p> <ol> <li><strong>EEG-XGBoost</strong>: A traditional gradient boosting algorithm optimized for EEG signal characteristics with custom feature extraction.</li> <li><strong>FBCNet-Refined</strong>: A convolutional neural network tailored for EEG data, leveraging frequency and spatial features with an OvR (one-vs-rest) strategy for multi-class classification.</li> <li><strong>Deformable Conformer</strong>: A novel architecture incorporating deformable attention mechanisms to improve generalization and reduce computational redundancy.</li> </ol> <h4 id="signal-mapping-and-vr-interaction">Signal Mapping and VR Interaction</h4> <ul> <li><strong>Control Mapping</strong>: Motor imagery results (e.g., left hand, right hand, or both legs) are mapped to directional commands in VR (e.g., turn left, turn right, or move forward).</li> <li><strong>VR Environment</strong>: A custom 3D maze built using Unity allows users to navigate using thought-controlled commands, completing tasks in an immersive setting.</li> </ul> <hr/> <h3 id="4-results-and-validation">4. Results and Validation</h3> <h4 id="model-performance">Model Performance</h4> <p>On the benchmark BCIC-Ⅳ-2a dataset, our Deformable Conformer model achieved state-of-the-art accuracy (81.71%), outperforming other methods by over 1%. For our custom local dataset, the ensemble model excelled in cross-session tests, achieving a classification accuracy of 59%.</p> <h4 id="real-time-interaction">Real-Time Interaction</h4> <p>In a real-time 3D maze experiment, users underwent a 5-minute calibration process to fine-tune the models. The system achieved a real-time classification accuracy of 75%, enabling users to navigate the maze successfully through motor imagery.</p> <hr/> <h3 id="5-challenges-and-future-directions">5. Challenges and Future Directions</h3> <h4 id="current-challenges">Current Challenges</h4> <ol> <li><strong>Real-Time Trade-Offs</strong>: Achieving both high accuracy and low latency remains a challenge.</li> <li><strong>User Variability</strong>: Calibration helps but does not fully mitigate signal variability across users.</li> <li><strong>Multi-Modal Integration</strong>: Combining EEG signals with other inputs (e.g., voice or gestures) could enhance usability and accuracy.</li> </ol> <h4 id="future-applications">Future Applications</h4> <ol> <li><strong>Entertainment</strong>: Develop thought-controlled VR games for immersive experiences.</li> <li><strong>Rehabilitation</strong>: Enable mobility for individuals with physical disabilities through intuitive interfaces.</li> <li><strong>Education and Training</strong>: Create virtual labs where users interact with the environment through motor imagery.</li> </ol> <hr/> <h3 id="6-conclusion">6. Conclusion</h3> <p>Our project demonstrates the potential of combining BCI and VR technologies to redefine interaction paradigms. By focusing on motor imagery-based brain signals, leveraging advanced machine learning models, and integrating with VR environments, we created a system that enables intuitive, thought-controlled interactions. This work not only lays the groundwork for future applications but also provides insights for overcoming the challenges in BCI and VR research.</p> <p>If you are intrigued by our project, feel free to visit our <a href="https://bci-vr.yunzinan.top">project website</a> or explore our <a href="https://github.com/BCI-NJU">GitHub repository</a>.</p> <hr/>]]></content><author><name></name></author><category term="project"/><summary type="html"><![CDATA[项目结题报告分享]]></summary></entry><entry><title type="html">大创项目中期进展分享</title><link href="https://bci-vr-nju.github.io/blog/2024/mid/" rel="alternate" type="text/html" title="大创项目中期进展分享"/><published>2024-10-11T12:30:00+00:00</published><updated>2024-10-11T12:30:00+00:00</updated><id>https://bci-vr-nju.github.io/blog/2024/mid</id><content type="html" xml:base="https://bci-vr-nju.github.io/blog/2024/mid/"><![CDATA[<h1 id="中期答辩材料">中期答辩材料</h1> <h2 id="一学术沙龙与合作">一、学术沙龙与合作</h2> <ul> <li><strong>时间：</strong> 2024/02/23 14:00-15:00</li> <li><strong>合作单位：</strong> 上海交通大学类脑计算和机器智能实验室（Brain-like Computing &amp; Machine Intelligence, BCMI）</li> <li><strong>指导专家：</strong> 郑伟龙副教授</li> <li><strong>讨论内容包括但不限于：</strong> <ul> <li>脑电波（EEG）数据的采集方式</li> <li>现有公开数据集的特点及优劣</li> <li>脑电波分类模型的能力及问题</li> <li>运动想象（Motor Imagery）脑电范式</li> <li>实时脑电采集与在线处理的经验</li> </ul> </li> </ul> <h2 id="二专利申请">二、专利申请</h2> <p>已向专利代理机构提交专利说明书，题为 <strong>“一款基于运动想象范式的通用实时脑机交互系统”</strong>。</p> <h2 id="三项目简介与阶段性进展">三、项目简介与阶段性进展</h2> <h3 id="项目目标">项目目标</h3> <p>本项目旨在开发一款基于运动想象范式的实时脑电采集、处理与反馈系统，用户可通过脑电波在虚拟现实（VR）环境中实现自由移动。</p> <h3 id="当前进展">当前进展</h3> <ol> <li>提出了 <strong>Deformable Conformer 模型</strong>，在公开数据集 BCIC-IV-2a 上达到了 <strong>SOTA 准确率（81.71%）</strong>，相比原模型参数量更小、推理速度更快。</li> <li>使用 Emotiv 设备，收集并整理本地离线数据集，并通过多种模型开展实验，评估数据集与模型质量。优质数据已开源至 GitHub。</li> <li>在实时在线数据中，模型准确率达到了 <strong>75%</strong>。</li> <li>搭建了 VR 迷宫 Demo，完成了从数据采集到 VR 控制的全链路实时系统。</li> <li>提交了相关专利申请。</li> </ol> <h2 id="四中期检查内容">四、中期检查内容</h2> <h3 id="1-已取得成果">1. 已取得成果</h3> <ul> <li>参与学术沙龙，发表论文和申请专利。</li> <li>完成基于实时脑电交互的 VR 系统搭建。</li> </ul> <h3 id="2-项目进展总结">2. 项目进展总结</h3> <ul> <li>离线数据集已实现高效分类。</li> <li>实时数据采集与处理准确率持续优化中。</li> </ul> <h2 id="五项目问题与解决方案">五、项目问题与解决方案</h2> <h3 id="存在问题">存在问题</h3> <ol> <li><strong>分类准确率不足</strong>：实时分类准确率约为 75%，需进一步提升。</li> <li><strong>系统响应延迟</strong>：当前 VR 系统每 4 秒采集一次信号，输出的动作粒度较粗。</li> <li><strong>跨会话一致性问题</strong>：预训练+微调不如小批量训练效果好，原因在于不同时间点的脑电信号分布差异。</li> </ol> <h3 id="解决方案">解决方案</h3> <h4 id="分类准确率提升">分类准确率提升</h4> <ul> <li>实时信号预处理：去噪、滤波。</li> <li>数据增强：补充实时采集的小样本。</li> <li>模型优化：设计适用于实时信号推理的架构（如 OvR、MoE、Bagging 等方法）。</li> </ul> <h4 id="系统流畅性优化">系统流畅性优化</h4> <ul> <li>在分类准确率提高的基础上，缩短信号采集时间，提高响应速度。</li> <li>提升动作颗粒度，例如细化为更小的移动单元。</li> </ul> <h4 id="跨会话一致性解决方案">跨会话一致性解决方案</h4> <ul> <li>数据标准化与归一化，进行数据校准。</li> <li>扩展数据规模与模型容量。</li> <li>结合文献研究，探索改进技术。</li> </ul> <h2 id="六未来计划">六、未来计划</h2> <h3 id="目标时间节点">目标时间节点</h3> <ol> <li><strong>2024年7月前：</strong> 提升实时分类准确率。</li> <li><strong>2024年10月前：</strong> 加入实时情感检测与反馈机制。</li> <li><strong>2024年12月前：</strong> 优化交互体验，提升系统稳定性。</li> </ol> <h2 id="七经费使用情况">七、经费使用情况</h2> <h3 id="预算详情">预算详情</h3> <table> <thead> <tr> <th>开支科目</th> <th>预算金额（元）</th> <th>前半阶段预算（元）</th> <th>后半阶段预算（元）</th> </tr> </thead> <tbody> <tr> <td>总经费</td> <td>12500</td> <td>5250</td> <td>7250</td> </tr> <tr> <td>计算分析测试费</td> <td>2000</td> <td>1000</td> <td>1000</td> </tr> <tr> <td>能源动力费</td> <td>500</td> <td>250</td> <td>250</td> </tr> <tr> <td>会议与差旅费</td> <td>3500</td> <td>1750</td> <td>1750</td> </tr> <tr> <td>文献检索费</td> <td>500</td> <td>250</td> <td>250</td> </tr> <tr> <td>论文出版与专利申请费</td> <td>6000</td> <td>2000</td> <td>4000</td> </tr> </tbody> </table> <h2 id="八周进展报告">八、周进展报告</h2> <table> <thead> <tr> <th>周期</th> <th>进展</th> </tr> </thead> <tbody> <tr> <td><strong>12.11-12.17</strong></td> <td>1. 文献调研；2. 寻找合适的开源数据集与模型；3. 初步探索数据采集与分类流程。</td> </tr> <tr> <td><strong>12.18-12.24</strong></td> <td>1. 测试 FBCNet 模型；2. 学习 BCIC 数据集使用；3. 配置 Emotiv 设备进行数据采集。</td> </tr> <tr> <td><strong>12.25-12.31</strong></td> <td>1. 解决 Emotiv 数据与标准数据集电极点位不一致问题；2. 调整数据分布方法；3. 分配寒假任务。</td> </tr> <tr> <td><strong>3.4-3.10</strong></td> <td>1. 汇总 FBCNet 与 Deformable Conformer 模型结果；2. 提交实验数据分析报告。</td> </tr> <tr> <td><strong>3.11-3.17</strong></td> <td>1. 测试本地数据集信号质量；2. 与交大专家交流学术成果；3. 完成数据与模型的联通。</td> </tr> <tr> <td><strong>3.18-3.24</strong></td> <td>1. 配置实时推理环境；2. 优化实时分类系统参数；3. 开始学习 Unity 开发。</td> </tr> <tr> <td><strong>3.25-3.31</strong></td> <td>1. 开发 VR 迷宫 Demo；2. 完成实时信号采集与分类优化。</td> </tr> <tr> <td><strong>4.1-4.7</strong></td> <td>1. 完成全链路实时交互系统搭建；2. 录制 Demo 视频。</td> </tr> </tbody> </table> <h2 id="九技术路线">九、技术路线</h2> <ol> <li>使用 <strong>Emotiv</strong> 设备实时采集脑电信号。</li> <li>数据通过深度学习模型分类，输出控制信号。</li> <li>控制信号驱动 VR 系统渲染并反馈给用户。</li> <li>系统拓展支持实时情感反馈。</li> </ol>]]></content><author><name></name></author><category term="project"/><summary type="html"><![CDATA[中级检查报告分享]]></summary></entry><entry><title type="html">大创项目前期规划</title><link href="https://bci-vr-nju.github.io/blog/2023/plan/" rel="alternate" type="text/html" title="大创项目前期规划"/><published>2023-09-26T22:08:00+00:00</published><updated>2023-09-26T22:08:00+00:00</updated><id>https://bci-vr-nju.github.io/blog/2023/plan</id><content type="html" xml:base="https://bci-vr-nju.github.io/blog/2023/plan/"><![CDATA[<h1 id="脑机接口bci与vr技术的融合与应用-项目前期规划">脑机接口(BCI)与VR技术的融合与应用 项目前期规划</h1> <h2 id="总体规划">总体规划</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/pattern-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/pattern-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/pattern-1400.webp"/> <img src="/assets/img/pattern.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> image source: [A VR Combined with MI-BCI Application for Upper Limb Rehabilitation of Stroke | IEEE Conference Publication | IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/8777805) </div> <p>上图所示的是使用VR和基于运动想象的脑机接口(MI-BCI)技术搭建的一个用于上肢的康复训练场景. 对于部分中风患者, 已经不能直接通过大脑控制移动自己的手臂, 但是可以证明其控制手臂的大脑信号仍然正常, 因此可以通过脑机读取相应的脑电信号, 识别出患者想要移动手臂的运动意图, 在VR构造的虚拟场景中, 挥动双臂, 像正常人一样打排球. 这样的交互模式有助于现实世界中重塑患者对双手的控制, 从而帮助患者康复训练.</p> <p>除了康复训练, BCI-VR的其他应用场景也具有与上图相似的范式. 具体来说, 都是首先通过读取EEG脑电信号, 经过信号处理识别算法后, 识别用户的意图, 再将其作为输入, 参与到VR的应用交互中, VR会根据大脑的意图作出相应的反馈.</p> <p>因此, 从实现路径来说, 分为以下几步:</p> <ol> <li>[准备阶段]查阅相关文献/emotiv文档/相关识别算法</li> <li>实现EEG信号的大脑意图识别(运动意图/情感的识别) ✨</li> <li>实现将EEG信号导入VR应用的接口</li> <li>实现VR交互的场景/交互模式构建</li> </ol> <h2 id="实现eeg信号的大脑意图识别运动意图情感的识别">实现EEG信号的大脑意图识别(运动意图/情感的识别)</h2> <p>这部分应该是整个项目比较fundamental的部分, 也是个人认为最重要的部分, 因此前中期主要会在这个阶段. 这个阶段的关键在于AI识别算法(如KNN, SVM等), 实现从原生的EEG信号转化为具体的意图, 例如:</p> <ul> <li>实现运动方向(前后左右)的识别, 可以用于在虚拟场景中的移动(navigation).</li> <li>实现情感的识别(positive/neutral/negative), 作为VR交互的全新维度.</li> </ul> <h2 id="实现将eeg信号导入vr应用的接口">实现将EEG信号导入VR应用的接口</h2> <p>由于上个阶段代码工作主要基于python实现, 而VR应用主要基于Unity开发, 因此需要实现软件层面的接口, 将从EEG设备读取并识别后的意图输入VR设备.</p> <h2 id="实现vr交互的场景交互模式构建">实现VR交互的场景/交互模式构建</h2> <p>这个阶段可以认为是一个Demo的阶段, 是将BCI技术的结果在VR场景中使用, 来增强VR的交互能力, 如上文提到, 实现hands-free navigation, 即在虚拟场景中直接通过大脑想象实现移动, 而不需要使用者真实移动; 此外, 可以在用户佩戴VR设备时实时读取脑电信号识别情感和放松程度, 来调整VR的显示内容等.</p> <p>上述的只是笔者目前想到的两种可行的应用场景, 一定还有许多有价值、有意思的场景, 因此具体的VR交互模式还有待构想.</p>]]></content><author><name></name></author><category term="project"/><summary type="html"><![CDATA[项目启动介绍]]></summary></entry><entry><title type="html">脑机接口(BCI)与VR技术的融合与应用-大创项目介绍</title><link href="https://bci-vr-nju.github.io/blog/2023/introduction/" rel="alternate" type="text/html" title="脑机接口(BCI)与VR技术的融合与应用-大创项目介绍"/><published>2023-09-13T22:08:00+00:00</published><updated>2023-09-13T22:08:00+00:00</updated><id>https://bci-vr-nju.github.io/blog/2023/introduction</id><content type="html" xml:base="https://bci-vr-nju.github.io/blog/2023/introduction/"><![CDATA[<h1 id="什么是脑机接口-脑机接口与vr能够产生怎样的化学反应">什么是脑机接口? 脑机接口与VR能够产生怎样的化学反应?</h1> <p>脑机接口(Brain Computer Interface)一直以来都是科幻小说、动漫与科幻电影的热点话题。不仅如此, 从马斯克创办Neuralink, 到米哈游入局投资脑机接口, 在现实生活中, BCI也获得了越来越多的注意力.</p> <p>相信不少人都看过《刀剑神域》这部动漫。在这部动漫中主角们通过脑机接口技术与虚拟现实技术前往游戏世界中进行冒险。依托于脑电信号的输出和头戴式设备提供的视觉输入, 动漫里的人物能够身临其境地沉浸于游戏世界. 这样的技术在现实中也存在该有多好!</p> <p>好的消息是, 得益于VR技术的日趋成熟和脑机接口的初步发展, 已经有不少科研团队和初创公司开始在脑机接口以及”脑机+VR”领域进行尝试, 如下图所示, 国外Galea公司就研发了集成了读取脑电信号的VR头戴设备, 能够获取实时的脑电信号来增强交互体验. 然而, 不得不指出的是, 在2023年的今天, 脑机接口的潜力还远没有被开发出来, 人们对大脑的诸多期待, 例如实现真正的脑-机沟通、将大脑数据上传电脑、实现数字永生等等, 还需要科研人员长期的努力.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/djsy-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/djsy-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/djsy-1400.webp"/> <img src="/assets/img/djsy.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/galea-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/galea-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/galea-1400.webp"/> <img src="/assets/img/galea.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 从动漫到现实: 我们所想象的一切, 正在变为现实. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="https://player.bilibili.com/player.html?aid=658284353&amp;bvid=BV1Bh4y1Z7kb&amp;cid=1192479953&amp;p=1" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="https://www.youtube.com/embed/uhLxggasiqE?si=b8VQAoCYKgE8VwUs" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"/> </figure> </div> </div> <p>看完上面的两个视频, 相信你会对脑机和”BCI-VR”产生更多的理解. 可以预见的是, 这项前沿技术正在快速崛起, 就像历史上的AI技术一样, 在多年后将会给人类生活的方方面面带来颠覆性的革命.</p> <p>为了让脑机接口技术落地, 与人们的日常生活产生更多的联系, 也得益于学校的硬件支持, 本大创项目选择将BCI与VR联系起来, 以脑机和虚拟现实两大前沿科技的交叉口作为出发点,</p> <ul> <li>一方面, 让脑机交互为虚拟现实技术赋能, 实现人脑直接与虚拟场景的交互, 让脑机技术作为人机交互的新渠道.</li> <li>另一方面, 让虚拟现实作为脑机技术的落脚点, 为脑机接口技术提供应用场景, 让脑机接口技术不仅助力残疾人士, 而是成为人人都能体验到的新兴技术.</li> </ul> <p>具体来说, 本大创项目计划实现的两条路线:</p> <ol> <li>[运动意图识别]目前, 在虚拟现实场景中的移动主要依赖用户在真实世界中的走动. 然而在真实世界中, 头戴VR设备的移动往往受限, 同时也不适合长时间走动. 通过读取大脑信号识别运动方向(前后左右)[已经有前辈同学的经验积累👏], 从而实现通过大脑发出运动意图来直接操纵虚拟场景中的移动, 获得身处梦境的沉浸感.</li> <li>[情感识别]情感脑机接口能够实现读取用户实时的心理状态(如积极/中立/消极, 以及专注/放松程度), 将实时读取的脑电信号解码为情感状态, 探索VR的全新交互维度.</li> </ol> <p>最后, 一句话介绍项目: 通过非侵入式设备读取脑电信号, 使用机器学习算法进行意图识别, 将结果输入VR, 从而实现人机交互模式上的探索与创新.</p>]]></content><author><name></name></author><category term="project"/><summary type="html"><![CDATA[项目启动介绍]]></summary></entry><entry><title type="html">Hello World!</title><link href="https://bci-vr-nju.github.io/blog/2023/theFirstBlog/" rel="alternate" type="text/html" title="Hello World!"/><published>2023-09-13T21:08:00+00:00</published><updated>2023-09-13T21:08:00+00:00</updated><id>https://bci-vr-nju.github.io/blog/2023/theFirstBlog</id><content type="html" xml:base="https://bci-vr-nju.github.io/blog/2023/theFirstBlog/"><![CDATA[<h2 id="这是一级标题">这是一级标题</h2> <p>测试<code class="language-plaintext highlighter-rouge">markdown</code>语法.</p> <ul> <li>1 <ul> <li>1.1</li> <li>1.2</li> </ul> </li> <li>2</li> </ul> <ol> <li>XXX</li> <li>XXX</li> </ol> <h3 id="这是二级标题">这是二级标题</h3> \[E = m\cdot c^2\] <h3 id="这是三级标题">这是三级标题</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Hello world!</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <blockquote> <p>this is a quote.</p> </blockquote>]]></content><author><name></name></author><category term="sample-posts"/><summary type="html"><![CDATA[建站测试]]></summary></entry><entry><title type="html">a post with bibliography</title><link href="https://bci-vr-nju.github.io/blog/2023/post-bibliography/" rel="alternate" type="text/html" title="a post with bibliography"/><published>2023-07-12T13:56:00+00:00</published><updated>2023-07-12T13:56:00+00:00</updated><id>https://bci-vr-nju.github.io/blog/2023/post-bibliography</id><content type="html" xml:base="https://bci-vr-nju.github.io/blog/2023/post-bibliography/"><![CDATA[<p>This post shows how to add bibliography to simple blog posts. If you would like something more academic, check the <a href="/blog/2021/distill/">distill style post</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="bib"/><summary type="html"><![CDATA[an example of a blog post with bibliography]]></summary></entry><entry><title type="html">a post with jupyter notebook</title><link href="https://bci-vr-nju.github.io/blog/2023/jupyter-notebook/" rel="alternate" type="text/html" title="a post with jupyter notebook"/><published>2023-07-04T12:57:00+00:00</published><updated>2023-07-04T12:57:00+00:00</updated><id>https://bci-vr-nju.github.io/blog/2023/jupyter-notebook</id><content type="html" xml:base="https://bci-vr-nju.github.io/blog/2023/jupyter-notebook/"><![CDATA[<p>To include a jupyter notebook in a post, you can use the following code:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{::nomarkdown}
{% assign jupyter_path = "assets/jupyter/blog.ipynb" | relative_url %}
{% capture notebook_exists %}{% file_exists assets/jupyter/blog.ipynb %}{% endcapture %}
{% if notebook_exists == "true" %}
    {% jupyter_notebook jupyter_path %}
{% else %}
    <span class="nt">&lt;p&gt;</span>Sorry, the notebook you are looking for does not exist.<span class="nt">&lt;/p&gt;</span>
{% endif %}
{:/nomarkdown}
</code></pre></div></div> <p>Let’s break it down: this is possible thanks to <a href="https://github.com/red-data-tools/jekyll-jupyter-notebook">Jekyll Jupyter Notebook plugin</a> that allows you to embed jupyter notebooks in your posts. It basically calls <a href="https://nbconvert.readthedocs.io/en/latest/usage.html#convert-html"><code class="language-plaintext highlighter-rouge">jupyter nbconvert --to html</code></a> to convert the notebook to an html page and then includes it in the post. Since <a href="https://jekyllrb.com/docs/configuration/markdown/">Kramdown</a> is the default Markdown renderer for Jekyll, we need to surround the call to the plugin with the <a href="https://kramdown.gettalong.org/syntax.html#extensions">::nomarkdown</a> tag so that it stops processing this part with Kramdown and outputs the content as-is.</p> <p>The plugin takes as input the path to the notebook, but it assumes the file exists. If you want to check if the file exists before calling the plugin, you can use the <code class="language-plaintext highlighter-rouge">file_exists</code> filter. This avoids getting a 404 error from the plugin and ending up displaying the main page inside of it instead. If the file does not exist, you can output a message to the user. The code displayed above outputs the following:</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/blog.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <p>Note that the jupyter notebook supports both light and dark themes.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="jupyter"/><summary type="html"><![CDATA[an example of a blog post with jupyter notebook]]></summary></entry><entry><title type="html">a post with custom blockquotes</title><link href="https://bci-vr-nju.github.io/blog/2023/custom-blockquotes/" rel="alternate" type="text/html" title="a post with custom blockquotes"/><published>2023-05-12T19:53:00+00:00</published><updated>2023-05-12T19:53:00+00:00</updated><id>https://bci-vr-nju.github.io/blog/2023/custom-blockquotes</id><content type="html" xml:base="https://bci-vr-nju.github.io/blog/2023/custom-blockquotes/"><![CDATA[<p>This post shows how to add custom styles for blockquotes. Based on <a href="https://github.com/sighingnow/jekyll-gitbook">jekyll-gitbook</a> implementation.</p> <p>We decided to support the same custom blockquotes as in <a href="https://sighingnow.github.io/jekyll-gitbook/jekyll/2022-06-30-tips_warnings_dangers.html">jekyll-gitbook</a>, which are also found in a lot of other sites’ styles. The styles definitions can be found on the <a href="https://github.com/alshedivat/al-folio/blob/master/_sass/_base.scss">_base.scss</a> file, more specifically:</p> <div class="language-scss highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/* Tips, warnings, and dangers */</span>
<span class="nc">.post</span> <span class="nc">.post-content</span> <span class="nt">blockquote</span> <span class="p">{</span>
    <span class="k">&amp;</span><span class="nc">.block-tip</span> <span class="p">{</span>
    <span class="nl">border-color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-tip-block</span><span class="p">);</span>
    <span class="nl">background-color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-tip-block-bg</span><span class="p">);</span>

    <span class="nt">p</span> <span class="p">{</span>
      <span class="nl">color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-tip-block-text</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="nt">h1</span><span class="o">,</span> <span class="nt">h2</span><span class="o">,</span> <span class="nt">h3</span><span class="o">,</span> <span class="nt">h4</span><span class="o">,</span> <span class="nt">h5</span><span class="o">,</span> <span class="nt">h6</span> <span class="p">{</span>
      <span class="nl">color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-tip-block-title</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="k">&amp;</span><span class="nc">.block-warning</span> <span class="p">{</span>
    <span class="nl">border-color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-warning-block</span><span class="p">);</span>
    <span class="nl">background-color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-warning-block-bg</span><span class="p">);</span>

    <span class="nt">p</span> <span class="p">{</span>
      <span class="nl">color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-warning-block-text</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="nt">h1</span><span class="o">,</span> <span class="nt">h2</span><span class="o">,</span> <span class="nt">h3</span><span class="o">,</span> <span class="nt">h4</span><span class="o">,</span> <span class="nt">h5</span><span class="o">,</span> <span class="nt">h6</span> <span class="p">{</span>
      <span class="nl">color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-warning-block-title</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="k">&amp;</span><span class="nc">.block-danger</span> <span class="p">{</span>
    <span class="nl">border-color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-danger-block</span><span class="p">);</span>
    <span class="nl">background-color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-danger-block-bg</span><span class="p">);</span>

    <span class="nt">p</span> <span class="p">{</span>
      <span class="nl">color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-danger-block-text</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="nt">h1</span><span class="o">,</span> <span class="nt">h2</span><span class="o">,</span> <span class="nt">h3</span><span class="o">,</span> <span class="nt">h4</span><span class="o">,</span> <span class="nt">h5</span><span class="o">,</span> <span class="nt">h6</span> <span class="p">{</span>
      <span class="nl">color</span><span class="p">:</span> <span class="nf">var</span><span class="p">(</span><span class="o">--</span><span class="n">global-danger-block-title</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>A regular blockquote can be used as following:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gt">&gt; This is a regular blockquote</span>
<span class="gt">&gt; and it can be used as usual</span>
</code></pre></div></div> <blockquote> <p>This is a regular blockquote and it can be used as usual</p> </blockquote> <p>These custom styles can be used by adding the specific class to the blockquote, as follows:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gt">&gt; ##### TIP</span>
<span class="gt">&gt;</span>
<span class="gt">&gt; A tip can be used when you want to give advice</span>
<span class="gt">&gt; related to a certain content.</span>
{: .block-tip }
</code></pre></div></div> <blockquote class="block-tip"> <h5 id="tip">TIP</h5> <p>A tip can be used when you want to give advice related to a certain content.</p> </blockquote> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gt">&gt; ##### WARNING</span>
<span class="gt">&gt;</span>
<span class="gt">&gt; This is a warning, and thus should</span>
<span class="gt">&gt; be used when you want to warn the user</span>
{: .block-warning }
</code></pre></div></div> <blockquote class="block-warning"> <h5 id="warning">WARNING</h5> <p>This is a warning, and thus should be used when you want to warn the user</p> </blockquote> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gt">&gt; ##### DANGER</span>
<span class="gt">&gt;</span>
<span class="gt">&gt; This is a danger zone, and thus should</span>
<span class="gt">&gt; be used carefully</span>
{: .block-danger }
</code></pre></div></div> <blockquote class="block-danger"> <h5 id="danger">DANGER</h5> <p>This is a danger zone, and thus should be used carefully</p> </blockquote>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="blockquotes"/><summary type="html"><![CDATA[an example of a blog post with custom blockquotes]]></summary></entry><entry><title type="html">a post with table of contents on a sidebar</title><link href="https://bci-vr-nju.github.io/blog/2023/sidebar-table-of-contents/" rel="alternate" type="text/html" title="a post with table of contents on a sidebar"/><published>2023-04-25T14:14:00+00:00</published><updated>2023-04-25T14:14:00+00:00</updated><id>https://bci-vr-nju.github.io/blog/2023/sidebar-table-of-contents</id><content type="html" xml:base="https://bci-vr-nju.github.io/blog/2023/sidebar-table-of-contents/"><![CDATA[<p>This post shows how to add a table of contents as a sidebar.</p> <h2 id="adding-a-table-of-contents">Adding a Table of Contents</h2> <p>To add a table of contents to a post as a sidebar, simply add</p> <div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">toc</span><span class="pi">:</span>
  <span class="na">sidebar</span><span class="pi">:</span> <span class="s">left</span>
</code></pre></div></div> <p>to the front matter of the post. The table of contents will be automatically generated from the headings in the post. If you wish to display the sidebar to the right, simply change <code class="language-plaintext highlighter-rouge">left</code> to <code class="language-plaintext highlighter-rouge">right</code>.</p> <h3 id="example-of-sub-heading-1">Example of Sub-Heading 1</h3> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h3 id="example-of-another-sub-heading-1">Example of another Sub-Heading 1</h3> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h2 data-toc-text="Customizing" id="customizing-your-table-of-contents">Customizing Your Table of Contents</h2> <p>If you want to learn more about how to customize the table of contents of your sidebar, you can check the <a href="https://afeld.github.io/bootstrap-toc/">bootstrap-toc</a> documentation. Notice that you can even customize the text of the heading that will be displayed on the sidebar.</p> <h3 id="example-of-sub-heading-2">Example of Sub-Heading 2</h3> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h3 id="example-of-another-sub-heading-2">Example of another Sub-Heading 2</h3> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="toc"/><category term="sidebar"/><summary type="html"><![CDATA[an example of a blog post with table of contents on a sidebar]]></summary></entry><entry><title type="html">a post with audios</title><link href="https://bci-vr-nju.github.io/blog/2023/audios/" rel="alternate" type="text/html" title="a post with audios"/><published>2023-04-25T10:25:00+00:00</published><updated>2023-04-25T10:25:00+00:00</updated><id>https://bci-vr-nju.github.io/blog/2023/audios</id><content type="html" xml:base="https://bci-vr-nju.github.io/blog/2023/audios/"><![CDATA[<p>This is an example post with audios. It supports local audio files.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/assets/audio/epicaly-short-113909.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="https://cdn.pixabay.com/download/audio/2022/06/25/audio_69a61cd6d6.mp3" controls=""/> </figure> </div> </div> <div class="caption"> A simple, elegant caption looks good between video rows, after each row, or doesn't have to be there at all. </div>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="audios"/><summary type="html"><![CDATA[this is what included audios could look like]]></summary></entry></feed>